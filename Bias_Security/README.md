<h1>Security and Bias adjustment of LLMs</h1>

<h2>Bias and Security of LLM in this work is considered as topics that LLM is expected to show a particular behvaior including avoid answering. In our example, we defined three different categories for LLM behavior.</h2>
<h3>Main Topic</h3>
<p>For Main topic we made the model to answer the questions comprehensively as it breaks down the problem and explains well.</p>

<h3>Forbidden Topic</h3>
<p>The model avoids answering these questions respectfully.</p>

<h3>General Questions</h3>
<p>The model only replies very short within a few words</p>

NB: In our example, we access our LLM from AzureOpenAI service. Any language model including GPT models by OpenAI API will work as well.
